{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeFi DEX Reputation Scoring Model\n",
    "\n",
    "This notebook contains the AI scoring logic for DEX (Decentralized Exchange) transactions.\n",
    "Your task is to integrate this logic into a production Kafka-based microservice.\n",
    "\n",
    "## Model Overview\n",
    "- **LP Scoring**: Analyzes liquidity provision patterns (deposits/withdraws)\n",
    "- **Swap Scoring**: Analyzes trading behavior and token diversity\n",
    "- **Combined Scoring**: Weighted average with user categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Tuple\n",
    "\n",
    "# Sample transaction data structure\n",
    "sample_wallet_data = {\n",
    "    \"wallet_address\": \"0x742d35Cc6634C0532925a3b8D4C9db96590e4265\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"protocolType\": \"dexes\",\n",
    "            \"transactions\": [\n",
    "                {\n",
    "                    \"document_id\": \"507f1f77bcf86cd799439011\",\n",
    "                    \"action\": \"swap\",\n",
    "                    \"timestamp\": 1703980800,\n",
    "                    \"caller\": \"0x742d35Cc6634C0532925a3b8D4C9db96590e4265\",\n",
    "                    \"protocol\": \"uniswap_v3\",\n",
    "                    \"poolId\": \"0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640\",\n",
    "                    \"poolName\": \"Uniswap V3 USDC/WETH 0.05%\",\n",
    "                    \"tokenIn\": {\n",
    "                        \"amount\": 1000000000,\n",
    "                        \"amountUSD\": 1000.0,\n",
    "                        \"address\": \"0xa0b86a33e6c3d4c3e6c3d4c3e6c3d4c3e6c3d4c3\",\n",
    "                        \"symbol\": \"USDC\"\n",
    "                    },\n",
    "                    \"tokenOut\": {\n",
    "                        \"amount\": 500000000000000000,\n",
    "                        \"amountUSD\": 1000.0,\n",
    "                        \"address\": \"0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\",\n",
    "                        \"symbol\": \"WETH\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"document_id\": \"507f1f77bcf86cd799439012\",\n",
    "                    \"action\": \"deposit\",\n",
    "                    \"timestamp\": 1703980900,\n",
    "                    \"caller\": \"0x742d35Cc6634C0532925a3b8D4C9db96590e4265\",\n",
    "                    \"protocol\": \"uniswap_v3\",\n",
    "                    \"poolId\": \"0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640\",\n",
    "                    \"poolName\": \"Uniswap V3 USDC/WETH 0.05%\",\n",
    "                    \"token0\": {\n",
    "                        \"amount\": 500000000,\n",
    "                        \"amountUSD\": 500.0,\n",
    "                        \"address\": \"0xa0b86a33e6c3d4c3e6c3d4c3e6c3d4c3e6c3d4c3\",\n",
    "                        \"symbol\": \"USDC\"\n",
    "                    },\n",
    "                    \"token1\": {\n",
    "                        \"amount\": 250000000000000000,\n",
    "                        \"amountUSD\": 500.0,\n",
    "                        \"address\": \"0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\",\n",
    "                        \"symbol\": \"WETH\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Sample data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions\n",
    "\n",
    "These functions convert JSON transaction data into pandas DataFrames for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dex_transactions(wallet_data: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert wallet transaction data to DataFrame for DEX analysis.\n",
    "    \n",
    "    Args:\n",
    "        wallet_data: Wallet data with transactions\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with processed transaction data\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    wallet_address = wallet_data['wallet_address']\n",
    "    \n",
    "    for category_data in wallet_data['data']:\n",
    "        if category_data['protocolType'] != 'dexes':\n",
    "            continue\n",
    "            \n",
    "        for tx in category_data['transactions']:\n",
    "            row = {\n",
    "                'wallet_address': wallet_address,\n",
    "                'document_id': tx['document_id'],\n",
    "                'action': tx['action'],\n",
    "                'timestamp': tx['timestamp'],\n",
    "                'protocol': tx.get('protocol', ''),\n",
    "                'pool_id': tx.get('poolId', ''),\n",
    "                'pool_name': tx.get('poolName', '')\n",
    "            }\n",
    "            \n",
    "            # Handle different transaction types\n",
    "            if tx['action'] == 'swap':\n",
    "                token_in = tx.get('tokenIn', {})\n",
    "                token_out = tx.get('tokenOut', {})\n",
    "                row['amount_usd'] = max(\n",
    "                    token_in.get('amountUSD', 0),\n",
    "                    token_out.get('amountUSD', 0)\n",
    "                )\n",
    "                row['token_in_symbol'] = token_in.get('symbol', '')\n",
    "                row['token_out_symbol'] = token_out.get('symbol', '')\n",
    "                \n",
    "            elif tx['action'] in ['deposit', 'withdraw']:\n",
    "                token0 = tx.get('token0', {})\n",
    "                token1 = tx.get('token1', {})\n",
    "                row['amount_usd'] = (\n",
    "                    token0.get('amountUSD', 0) + token1.get('amountUSD', 0)\n",
    "                )\n",
    "                row['token0_symbol'] = token0.get('symbol', '')\n",
    "                row['token1_symbol'] = token1.get('symbol', '')\n",
    "            \n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Test preprocessing\n",
    "df = preprocess_dex_transactions(sample_wallet_data)\n",
    "print(f\"Processed {len(df)} transactions\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LP (Liquidity Provider) Scoring Functions\n",
    "\n",
    "These functions analyze liquidity provision patterns and calculate LP reputation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lp_features(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate LP-specific features from transaction data.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with DEX transactions\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with LP features\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Filter LP transactions\n",
    "    deposits = df[df['action'] == 'deposit']\n",
    "    withdraws = df[df['action'] == 'withdraw']\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_deposit_usd = deposits['amount_usd'].sum() if not deposits.empty else 0.0\n",
    "    total_withdraw_usd = withdraws['amount_usd'].sum() if not withdraws.empty else 0.0\n",
    "    num_deposits = len(deposits)\n",
    "    num_withdraws = len(withdraws)\n",
    "    \n",
    "    # Calculate withdraw ratio\n",
    "    withdraw_ratio = total_withdraw_usd / total_deposit_usd if total_deposit_usd > 0 else 0.0\n",
    "    \n",
    "    # Calculate account age\n",
    "    if not df.empty:\n",
    "        account_age_days = (df['timestamp'].max() - df['timestamp'].min()) / 86400\n",
    "    else:\n",
    "        account_age_days = 0.0\n",
    "    \n",
    "    # Calculate average holding time\n",
    "    avg_hold_time_days = calculate_holding_time(deposits, withdraws)\n",
    "    \n",
    "    # Unique pools\n",
    "    unique_pools = df['pool_id'].nunique()\n",
    "    \n",
    "    return {\n",
    "        'total_deposit_usd': total_deposit_usd,\n",
    "        'total_withdraw_usd': total_withdraw_usd,\n",
    "        'num_deposits': num_deposits,\n",
    "        'num_withdraws': num_withdraws,\n",
    "        'withdraw_ratio': withdraw_ratio,\n",
    "        'avg_hold_time_days': avg_hold_time_days,\n",
    "        'account_age_days': account_age_days,\n",
    "        'unique_pools': unique_pools\n",
    "    }\n",
    "\n",
    "def calculate_holding_time(deposits: pd.DataFrame, withdraws: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate realistic holding time by matching deposits to withdraws.\n",
    "    \"\"\"\n",
    "    if deposits.empty:\n",
    "        return 0.0\n",
    "    \n",
    "    holding_times = []\n",
    "    current_time = datetime.now().timestamp()\n",
    "    \n",
    "    for _, deposit in deposits.iterrows():\n",
    "        deposit_time = deposit['timestamp']\n",
    "        \n",
    "        # Find next withdraw after this deposit\n",
    "        future_withdraws = withdraws[withdraws['timestamp'] > deposit_time]\n",
    "        \n",
    "        if not future_withdraws.empty:\n",
    "            # Use earliest withdraw\n",
    "            withdraw_time = future_withdraws['timestamp'].min()\n",
    "            holding_time = (withdraw_time - deposit_time) / 86400  # Convert to days\n",
    "        else:\n",
    "            # No withdraw found, use current time\n",
    "            holding_time = (current_time - deposit_time) / 86400\n",
    "        \n",
    "        holding_times.append(holding_time)\n",
    "    \n",
    "    return np.mean(holding_times) if holding_times else 0.0\n",
    "\n",
    "def calculate_lp_score(features: Dict[str, float]) -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Calculate LP reputation score based on features.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (score, score_breakdown)\n",
    "    \"\"\"\n",
    "    if not features:\n",
    "        return 0.0, {}\n",
    "    \n",
    "    # Volume score (0-300 points)\n",
    "    volume_score = min(features['total_deposit_usd'] / 10000 * 300, 300)\n",
    "    \n",
    "    # Frequency score (0-200 points)\n",
    "    frequency_score = min(features['num_deposits'] * 20, 200)\n",
    "    \n",
    "    # Retention score (0-250 points) - higher is better for low withdraw ratio\n",
    "    retention_score = max(0, (1 - features['withdraw_ratio']) * 250)\n",
    "    \n",
    "    # Holding time score (0-150 points)\n",
    "    holding_score = min(features['avg_hold_time_days'] / 30 * 150, 150)\n",
    "    \n",
    "    # Diversity score (0-100 points)\n",
    "    diversity_score = min(features['unique_pools'] * 20, 100)\n",
    "    \n",
    "    total_score = volume_score + frequency_score + retention_score + holding_score + diversity_score\n",
    "    \n",
    "    breakdown = {\n",
    "        'volume_score': volume_score,\n",
    "        'frequency_score': frequency_score,\n",
    "        'retention_score': retention_score,\n",
    "        'holding_score': holding_score,\n",
    "        'diversity_score': diversity_score,\n",
    "        'total_lp_score': total_score\n",
    "    }\n",
    "    \n",
    "    return total_score, breakdown\n",
    "\n",
    "# Test LP scoring\n",
    "lp_features = calculate_lp_features(df)\n",
    "lp_score, lp_breakdown = calculate_lp_score(lp_features)\n",
    "print(f\"LP Features: {lp_features}\")\n",
    "print(f\"LP Score: {lp_score}\")\n",
    "print(f\"LP Breakdown: {lp_breakdown}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swap Scoring Functions\n",
    "\n",
    "These functions analyze trading behavior and calculate swap reputation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_swap_features(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate swap-specific features from transaction data.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with DEX transactions\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with swap features\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Filter swap transactions\n",
    "    swaps = df[df['action'] == 'swap']\n",
    "    \n",
    "    if swaps.empty:\n",
    "        return {\n",
    "            'total_swap_volume': 0.0,\n",
    "            'num_swaps': 0,\n",
    "            'unique_pools_swapped': 0,\n",
    "            'avg_swap_size': 0.0,\n",
    "            'token_diversity_score': 0,\n",
    "            'swap_frequency_score': 0.0\n",
    "        }\n",
    "    \n",
    "    # Basic swap metrics\n",
    "    total_swap_volume = swaps['amount_usd'].sum()\n",
    "    num_swaps = len(swaps)\n",
    "    unique_pools_swapped = swaps['pool_id'].nunique()\n",
    "    avg_swap_size = total_swap_volume / num_swaps if num_swaps > 0 else 0.0\n",
    "    \n",
    "    # Token diversity analysis\n",
    "    token_diversity_score = calculate_token_diversity(swaps)\n",
    "    \n",
    "    # Swap frequency analysis\n",
    "    swap_frequency_score = calculate_swap_frequency(swaps)\n",
    "    \n",
    "    return {\n",
    "        'total_swap_volume': total_swap_volume,\n",
    "        'num_swaps': num_swaps,\n",
    "        'unique_pools_swapped': unique_pools_swapped,\n",
    "        'avg_swap_size': avg_swap_size,\n",
    "        'token_diversity_score': token_diversity_score,\n",
    "        'swap_frequency_score': swap_frequency_score\n",
    "    }\n",
    "\n",
    "def calculate_token_diversity(swaps: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Calculate token diversity score based on variety of tokens traded.\n",
    "    \"\"\"\n",
    "    if swaps.empty:\n",
    "        return 0\n",
    "    \n",
    "    # Define stable tokens\n",
    "    stable_tokens = {'USDC', 'USDT', 'DAI', 'LUSD', 'USDP', 'TUSD', 'FRAX'}\n",
    "    \n",
    "    # Get all unique tokens\n",
    "    tokens_in = set(swaps['token_in_symbol'].dropna())\n",
    "    tokens_out = set(swaps['token_out_symbol'].dropna())\n",
    "    all_tokens = tokens_in.union(tokens_out)\n",
    "    \n",
    "    # Count stable vs volatile tokens\n",
    "    stable_count = len(all_tokens.intersection(stable_tokens))\n",
    "    volatile_count = len(all_tokens) - stable_count\n",
    "    \n",
    "    # Weighted diversity score (volatile tokens worth more)\n",
    "    diversity_score = stable_count * 10 + volatile_count * 15\n",
    "    \n",
    "    return min(diversity_score, 150)  # Cap at 150 points\n",
    "\n",
    "def calculate_swap_frequency(swaps: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate swap frequency score based on trading patterns.\n",
    "    \"\"\"\n",
    "    if swaps.empty or len(swaps) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate time between swaps\n",
    "    swaps_sorted = swaps.sort_values('timestamp')\n",
    "    time_diffs = swaps_sorted['timestamp'].diff().dropna()\n",
    "    \n",
    "    # Convert to hours\n",
    "    time_diffs_hours = time_diffs / 3600\n",
    "    \n",
    "    # Calculate average time between swaps\n",
    "    avg_time_between_swaps = time_diffs_hours.mean()\n",
    "    \n",
    "    # Score based on frequency (lower time = higher score)\n",
    "    if avg_time_between_swaps <= 1:  # Less than 1 hour\n",
    "        return 100.0\n",
    "    elif avg_time_between_swaps <= 24:  # Less than 1 day\n",
    "        return 80.0\n",
    "    elif avg_time_between_swaps <= 168:  # Less than 1 week\n",
    "        return 60.0\n",
    "    elif avg_time_between_swaps <= 720:  # Less than 1 month\n",
    "        return 40.0\n",
    "    else:\n",
    "        return 20.0\n",
    "\n",
    "def calculate_swap_score(features: Dict[str, float]) -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Calculate swap reputation score based on features.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (score, score_breakdown)\n",
    "    \"\"\"\n",
    "    if not features:\n",
    "        return 0.0, {}\n",
    "    \n",
    "    # Volume score (0-250 points)\n",
    "    volume_score = min(features['total_swap_volume'] / 50000 * 250, 250)\n",
    "    \n",
    "    # Frequency score (0-200 points)\n",
    "    frequency_score = min(features['num_swaps'] * 10, 200)\n",
    "    \n",
    "    # Diversity score (0-150 points) - from token diversity\n",
    "    diversity_score = features['token_diversity_score']\n",
    "    \n",
    "    # Activity score (0-100 points) - from swap frequency\n",
    "    activity_score = features['swap_frequency_score']\n",
    "    \n",
    "    # Pool diversity score (0-100 points)\n",
    "    pool_diversity_score = min(features['unique_pools_swapped'] * 25, 100)\n",
    "    \n",
    "    total_score = volume_score + frequency_score + diversity_score + activity_score + pool_diversity_score\n",
    "    \n",
    "    breakdown = {\n",
    "        'volume_score': volume_score,\n",
    "        'frequency_score': frequency_score,\n",
    "        'diversity_score': diversity_score,\n",
    "        'activity_score': activity_score,\n",
    "        'pool_diversity_score': pool_diversity_score,\n",
    "        'total_swap_score': total_score\n",
    "    }\n",
    "    \n",
    "    return total_score, breakdown\n",
    "\n",
    "# Test swap scoring\n",
    "swap_features = calculate_swap_features(df)\n",
    "swap_score, swap_breakdown = calculate_swap_score(swap_features)\n",
    "print(f\"Swap Features: {swap_features}\")\n",
    "print(f\"Swap Score: {swap_score}\")\n",
    "print(f\"Swap Breakdown: {swap_breakdown}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Scoring and User Tagging\n",
    "\n",
    "Final functions to combine LP and Swap scores and generate user tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_tags(lp_features: Dict, swap_features: Dict) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate user tags based on LP and swap behavior.\n",
    "    \n",
    "    Returns:\n",
    "        List of user tags\n",
    "    \"\"\"\n",
    "    tags = []\n",
    "    \n",
    "    # LP-based tags\n",
    "    if lp_features.get('total_deposit_usd', 0) > 100000:\n",
    "        tags.append('Whale LP')\n",
    "    elif lp_features.get('total_deposit_usd', 0) > 10000:\n",
    "        tags.append('Large LP')\n",
    "    elif lp_features.get('total_deposit_usd', 0) > 1000:\n",
    "        tags.append('Medium LP')\n",
    "    elif lp_features.get('total_deposit_usd', 0) > 0:\n",
    "        tags.append('Small LP')\n",
    "    \n",
    "    # Holding behavior tags\n",
    "    if lp_features.get('avg_hold_time_days', 0) > 90:\n",
    "        tags.append('Long-term Holder')\n",
    "    elif lp_features.get('avg_hold_time_days', 0) > 30:\n",
    "        tags.append('Medium-term Holder')\n",
    "    elif lp_features.get('avg_hold_time_days', 0) > 0:\n",
    "        tags.append('Short-term Holder')\n",
    "    \n",
    "    # Swap-based tags\n",
    "    if swap_features.get('total_swap_volume', 0) > 500000:\n",
    "        tags.append('Whale Trader')\n",
    "    elif swap_features.get('total_swap_volume', 0) > 50000:\n",
    "        tags.append('Large Trader')\n",
    "    elif swap_features.get('total_swap_volume', 0) > 5000:\n",
    "        tags.append('Active Trader')\n",
    "    elif swap_features.get('total_swap_volume', 0) > 0:\n",
    "        tags.append('Casual Trader')\n",
    "    \n",
    "    # Frequency tags\n",
    "    if swap_features.get('num_swaps', 0) > 100:\n",
    "        tags.append('High Frequency Trader')\n",
    "    elif swap_features.get('num_swaps', 0) > 20:\n",
    "        tags.append('Regular Trader')\n",
    "    \n",
    "    # Diversity tags\n",
    "    if swap_features.get('token_diversity_score', 0) > 100:\n",
    "        tags.append('Diversified Trader')\n",
    "    elif lp_features.get('unique_pools', 0) > 3:\n",
    "        tags.append('Multi-Pool LP')\n",
    "    \n",
    "    return tags\n",
    "\n",
    "def calculate_final_score(lp_score: float, swap_score: float, \n",
    "                         lp_features: Dict, swap_features: Dict) -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Calculate final combined reputation score.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (final_score, complete_features)\n",
    "    \"\"\"\n",
    "    # Weight LP and Swap scores (60% LP, 40% Swap)\n",
    "    lp_weight = 0.6\n",
    "    swap_weight = 0.4\n",
    "    \n",
    "    final_score = (lp_score * lp_weight) + (swap_score * swap_weight)\n",
    "    \n",
    "    # Generate user tags\n",
    "    user_tags = generate_user_tags(lp_features, swap_features)\n",
    "    \n",
    "    # Combine all features\n",
    "    complete_features = {\n",
    "        **lp_features,\n",
    "        **swap_features,\n",
    "        'user_tags': user_tags,\n",
    "        'lp_score': lp_score,\n",
    "        'swap_score': swap_score,\n",
    "        'final_score': final_score\n",
    "    }\n",
    "    \n",
    "    return final_score, complete_features\n",
    "\n",
    "def process_wallet_complete(wallet_data: Dict) -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Complete wallet processing pipeline.\n",
    "    \n",
    "    This is the main function you need to implement in your server.\n",
    "    \n",
    "    Args:\n",
    "        wallet_data: Raw wallet data from Kafka\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (final_score, features)\n",
    "    \"\"\"\n",
    "    # Step 1: Preprocess data\n",
    "    df = preprocess_dex_transactions(wallet_data)\n",
    "    \n",
    "    if df.empty:\n",
    "        return 0.0, {'error': 'No valid transactions found'}\n",
    "    \n",
    "    # Step 2: Calculate LP features and score\n",
    "    lp_features = calculate_lp_features(df)\n",
    "    lp_score, lp_breakdown = calculate_lp_score(lp_features)\n",
    "    \n",
    "    # Step 3: Calculate Swap features and score\n",
    "    swap_features = calculate_swap_features(df)\n",
    "    swap_score, swap_breakdown = calculate_swap_score(swap_features)\n",
    "    \n",
    "    # Step 4: Calculate final score and combine features\n",
    "    final_score, complete_features = calculate_final_score(\n",
    "        lp_score, swap_score, lp_features, swap_features\n",
    "    )\n",
    "    \n",
    "    # Add score breakdowns\n",
    "    complete_features['score_breakdown'] = {\n",
    "        'lp_breakdown': lp_breakdown,\n",
    "        'swap_breakdown': swap_breakdown\n",
    "    }\n",
    "    \n",
    "    return final_score, complete_features\n",
    "\n",
    "# Test complete pipeline\n",
    "final_score, features = process_wallet_complete(sample_wallet_data)\n",
    "print(f\"\\nFinal Score: {final_score:.2f}\")\n",
    "print(f\"User Tags: {features['user_tags']}\")\n",
    "print(f\"LP Score: {features['lp_score']:.2f}\")\n",
    "print(f\"Swap Score: {features['swap_score']:.2f}\")\n",
    "\n",
    "# Expected output format for your server\n",
    "expected_output = {\n",
    "    'wallet_address': sample_wallet_data['wallet_address'],\n",
    "    'zscore': f\"{final_score:.18f}\",  # 18 decimal places for blockchain compatibility\n",
    "    'timestamp': int(datetime.now().timestamp()),\n",
    "    'categories': [{\n",
    "        'category': 'dexes',\n",
    "        'score': final_score,\n",
    "        'transaction_count': len(df),\n",
    "        'features': {\n",
    "            k: v for k, v in features.items() \n",
    "            if k not in ['score_breakdown', 'user_tags']\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "\n",
    "print(f\"\\nExpected Kafka Output:\")\n",
    "print(json.dumps(expected_output, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
